# This is a basic workflow to help you get started with Actions

name: CI

# Controls when the workflow will run
on:
  # Triggers the workflow on push or pull request events but only for the main branch
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "build"
  build:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v2
      
      # Runs a single command using the runners shell
      - name: Run a one-line script
        run: |
          python -V
          whereis python
      
      - name: Setup Python
        uses: actions/setup-python@v2.2.2
        with:
          # Version range or exact version of a Python version to use, using SemVer's version range syntax.
          python-version: 3.6 # optional, default is 3.x

      - name: Run a one-line script
        run: |
          python -V
          whereis python
          java -version
          whereis java
          
      - name: Setup Java JDK
        uses: actions/setup-java@v2.1.0
        with:
          # The Java version to set up. Takes a whole or semver Java version. See examples of supported syntax in README file
          java-version: 8
          distribution: 'adopt'

      # Runs a single command using the runners shell
      - name: Run a one-line script
        run: java -version

      - name: Setup Apache Spark
        # You may pin to the exact commit or the version.
        # uses: vemonet/setup-spark@e8cb86fc6de0c73c110a9744d8a0d526384b5b2d
        uses: vemonet/setup-spark@v1
        with:
          # Apache Spark version to install, see https://spark.apache.org/downloads.html
          spark-version: 2.4.8
          # Hadoop version
          hadoop-version: 2.6 # optional, default is 3.2
      
      - name: test spark installation
        run: spark-submit --version
        
      - name: Install genalog
        run: |
          pip install --upgrade pip setuptools wheel
          pip install -r requirements.txt
          pip install -r requirements-dev.txt
          pip install -e .
      
      
